{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with Image or Webcam on Ryzen AI\n",
    "\n",
    "This example demonstrates the object detection model inference on the embedded Neural Processing Unit (NPU) in your AMD Ryzen AI enabled PC with either single image or the live webcam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi>=0.104.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 2)) (0.115.11)\n",
      "Requirement already satisfied: uvicorn>=0.23.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 3)) (0.34.0)\n",
      "Requirement already satisfied: pydantic>=2.4.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 4)) (2.10.6)\n",
      "Requirement already satisfied: pydantic-settings>=2.0.3 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 5)) (2.8.1)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.6 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 7)) (0.0.20)\n",
      "Requirement already satisfied: firebase-admin>=6.2.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (6.6.0)\n",
      "Requirement already satisfied: aiohttp>=3.8.6 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 13)) (3.11.13)\n",
      "Requirement already satisfied: Pillow>=10.0.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 16)) (11.1.0)\n",
      "Requirement already satisfied: numpy>=1.25.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 17)) (2.0.2)\n",
      "Requirement already satisfied: opencv-python>=4.8.1.78 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 18)) (4.11.0.86)\n",
      "Requirement already satisfied: tensorflow>=2.14.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (2.18.0)\n",
      "Requirement already satisfied: loguru>=0.7.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 24)) (0.7.3)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from fastapi>=0.104.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 2)) (0.46.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from fastapi>=0.104.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from uvicorn>=0.23.2->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 3)) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from uvicorn>=0.23.2->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from pydantic>=2.4.2->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from pydantic>=2.4.2->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 4)) (2.27.2)\n",
      "Requirement already satisfied: cachecontrol>=0.12.14 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (0.14.2)\n",
      "Requirement already satisfied: google-api-python-client>=1.7.8 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (2.162.0)\n",
      "Requirement already satisfied: google-cloud-storage>=1.37.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: pyjwt>=2.5.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from pyjwt[crypto]>=2.5.0->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (2.10.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=1.22.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (2.24.1)\n",
      "Requirement already satisfied: google-cloud-firestore>=2.19.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (2.20.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from aiohttp>=3.8.6->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 13)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from aiohttp>=3.8.6->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 13)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from aiohttp>=3.8.6->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 13)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from aiohttp>=3.8.6->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 13)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from aiohttp>=3.8.6->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 13)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from aiohttp>=3.8.6->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 13)) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from aiohttp>=3.8.6->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 13)) (1.18.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (75.8.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (0.4.1)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from loguru>=0.7.2->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 24)) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from loguru>=0.7.2->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 24)) (1.2.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from cachecontrol>=0.12.14->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (1.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (1.68.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (1.26.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (2.38.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (1.70.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-api-python-client>=1.7.8->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-api-python-client>=1.7.8->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-api-python-client>=1.7.8->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (4.1.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-cloud-firestore>=2.19.0->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (2.4.2)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-cloud-storage>=1.37.1->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-cloud-storage>=1.37.1->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (1.6.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from pyjwt[crypto]>=2.5.0->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (44.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.104.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.8.6->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 13)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.104.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (0.45.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (1.17.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=1.7.8->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (3.2.1)\n",
      "Requirement already satisfied: rich in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (3.1.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (2.22)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin>=6.2.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 10)) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\isaia\\hackathon\\ryzenai_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.14.0->-r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt (line 19)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Before starting, be sure you've installed the requirements listed in the requirements.txt file:\n",
    "%pip install -r C:\\Users\\isaia\\Hackathon\\EcoVision\\backend\\app\\requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get Model from Ryzen AI model zoo\n",
    "The yolov8 model from [Ryzen AI model zoo](https://huggingface.co/amd) will be applied in this example. You may choose any other object detection models with tiny difference in the pre and post processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\isaia\\\\Hackathon\\\\RyzenAI-SW\\\\tutorial\\\\yolov8\\\\yolov8_python\\\\yolov8m.onnx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('C:/Users/isaia/Hackathon/RyzenAI-SW/tutorial/yolov8/yolov8_python'))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from huggingface_hub import hf_hub_download\n",
    "from yolov8_utils import get_directories, non_max_suppression, plot_images, output_to_target\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Notebook \n",
    "# dependencies\n",
    "from huggingface_hub import hf_hub_download\n",
    "from yolov8_utils import get_directories\n",
    "\n",
    "current_dir = get_directories()\n",
    "\n",
    "# Download Yolov8 model from Ryzen AI model zoo. Registration is required before download.\n",
    "hf_hub_download(repo_id=\"amd/yolov8m\", filename=\"yolov8m.onnx\", local_dir=str(current_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model inference on NPU with webcam\n",
    "\n",
    "Now we have validated the the model with image., and we will use the webcam as live input to do the inference on NPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the directory containing yolov8_utils.py to the Python path\n",
    "sys.path.append(os.path.abspath('C:/Users/isaia/Hackathon/RyzenAI-SW/tutorial/yolov8/yolov8_python'))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from huggingface_hub import hf_hub_download\n",
    "from yolov8_utils import get_directories, non_max_suppression, plot_images, output_to_target\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Notebook dependencies\n",
    "current_dir = get_directories()\n",
    "\n",
    "# Download Yolov8 model from Ryzen AI model zoo. Registration is required before download.\n",
    "onnx_model_path = hf_hub_download(repo_id=\"amd/yolov8m\", filename=\"yolov8m.onnx\", local_dir=str(current_dir))\n",
    "\n",
    "# Load labels of coco dataset\n",
    "coco_names_path = 'C:/Users/isaia/Hackathon/EcoVision/backend/data/coco.names'\n",
    "with open(coco_names_path, 'r') as f:\n",
    "    names = f.read().splitlines()\n",
    "\n",
    "print(f\"Class names: {names}\")\n",
    "\n",
    "imgsz = [640, 640]\n",
    "\n",
    "# Point to the config file path used for the VitisAI Execution Provider\n",
    "config_file_path = \"./vaip_config.json\"\n",
    "\n",
    "npu_options = onnxruntime.SessionOptions()\n",
    "\n",
    "npu_session = onnxruntime.InferenceSession(\n",
    "    onnx_model_path,\n",
    "    providers = ['VitisAIExecutionProvider'],\n",
    "    sess_options=npu_options,\n",
    "    provider_options=[{'config_file': config_file_path}]\n",
    ")\n",
    "\n",
    "# Paths to anchors and strides files\n",
    "anchors_path = 'C:/Users/isaia/Hackathon/RyzenAI-SW/tutorial/yolov8/yolov8_python/anchors.npy'\n",
    "strides_path = 'C:/Users/isaia/Hackathon/RyzenAI-SW/tutorial/yolov8/yolov8_python/strides.npy'\n",
    "\n",
    "# Define Distribution Focal Loss\n",
    "class DFL(nn.Module):\n",
    "    def __init__(self, c1=16):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)\n",
    "        x = torch.arange(c1, dtype=torch.float)\n",
    "        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))\n",
    "        self.c1 = c1\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, a = x.shape  # batch, channels, anchors\n",
    "        return self.conv(x.view(b, 4, self.c1, a).transpose(2, 1).softmax(1)).view(b, 4, a)\n",
    "\n",
    "# Convert distance format to bounding box\n",
    "def dist2bbox(distance, anchor_points, xywh=True, dim=-1):\n",
    "    lt, rb = torch.split(distance, 2, dim)\n",
    "    x1y1 = anchor_points - lt\n",
    "    x2y2 = anchor_points + rb\n",
    "    if xywh:\n",
    "        c_xy = (x1y1 + x2y2) / 2\n",
    "        wh = x2y2 - x1y1\n",
    "        return torch.cat((c_xy, wh), dim)\n",
    "    return torch.cat((x1y1, x2y2), dim)\n",
    "\n",
    "\n",
    "# Corrected post-processing function\n",
    "def post_process(x):\n",
    "    \"\"\"\n",
    "    Post-process the model's raw output to extract bounding boxes and class scores.\n",
    "    \"\"\"\n",
    "    dfl = DFL(16)\n",
    "\n",
    "    box_features = 64  # 4 * 16 DFL bins\n",
    "    class_features = 80  # Original number of COCO classes\n",
    "    \n",
    "    # Use the correct paths for anchors and strides\n",
    "    anchors_path = 'C:/Users/isaia/Hackathon/EcoVision/backend/data/anchors.npy'\n",
    "    strides_path = 'C:/Users/isaia/Hackathon/EcoVision/backend/data/strides.npy'\n",
    "    \n",
    "    # Load anchors and strides\n",
    "    anchors = torch.tensor(np.load(anchors_path))\n",
    "    strides = torch.tensor(np.load(strides_path))\n",
    "\n",
    "    batch_size = x[0].shape[0]\n",
    "\n",
    "    # Reshape outputs to [batch, channels, total_points]\n",
    "    reshaped_outputs = [xi.view(batch_size, xi.shape[1], -1) for xi in x]\n",
    "\n",
    "    # Concatenate outputs along spatial dimension\n",
    "    combined_output = torch.cat(reshaped_outputs, dim=2)\n",
    "\n",
    "    # Split into bounding box regression and class probabilities\n",
    "    # Keep the original split sizes to match the model's output structure\n",
    "    box, cls = combined_output.split((box_features, class_features), dim=1)\n",
    "\n",
    "    # Convert to bounding boxes\n",
    "    dbox = dist2bbox(dfl(box), anchors.unsqueeze(0), xywh=True, dim=1) * strides\n",
    "\n",
    "    # Apply sigmoid activation to class predictions\n",
    "    cls = cls.sigmoid()\n",
    "    \n",
    "    # Map COCO class indices to your custom classes\n",
    "    # For example, if you want to detect bottles (COCO class 39) as \"plastic\"\n",
    "    # and cups (COCO class 41) as \"glass\", etc.\n",
    "    \n",
    "    # Create a new tensor for your 6 classes\n",
    "    custom_cls = torch.zeros((batch_size, 6, cls.shape[2]), device=cls.device)\n",
    "    \n",
    "    # Map specific COCO classes to your custom classes\n",
    "    # These are examples, adjust according to what you want to detect\n",
    "    # You can check COCO class indices here: https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n",
    "    \n",
    "    # Plastic: map bottle (39), plastic bottle (bottles are 39 in COCO)\n",
    "    custom_cls[:, 0, :] = cls[:, 39, :]  # Bottle -> Plastic\n",
    "    \n",
    "    # Metal: map cans and metal objects (can opener is not in COCO, use knife (49) as example)\n",
    "    custom_cls[:, 1, :] = cls[:, 49, :]  # Knife -> Metal\n",
    "    \n",
    "    # Paper: map book (73), paper doesn't have direct COCO class\n",
    "    custom_cls[:, 2, :] = cls[:, 73, :]  # Book -> Paper\n",
    "    \n",
    "    # Glass: map wine glass (40), cup (41) \n",
    "    custom_cls[:, 3, :] = torch.max(cls[:, 40, :], cls[:, 41, :])  # Wine glass or cup -> Glass\n",
    "    \n",
    "    # Organic: map fruits, vegetables, food (e.g., apple (47), orange (49), banana (52))\n",
    "    custom_cls[:, 4, :] = torch.max(torch.max(cls[:, 47, :], cls[:, 49, :]), cls[:, 52, :])  # Fruits -> Organic\n",
    "    \n",
    "    # Other: map other common objects like cell phone (67)\n",
    "    custom_cls[:, 5, :] = cls[:, 67, :]  # Cell phone -> Other\n",
    "    \n",
    "    return torch.cat((dbox, custom_cls), dim=1)\n",
    "\n",
    "# Then in your main detection loop, after obtaining the predictions:\n",
    "preds = non_max_suppression(\n",
    "    preds, \n",
    "    0.25,  # confidence threshold \n",
    "    0.7,   # IoU threshold\n",
    "    agnostic=False, \n",
    "    max_det=300, \n",
    "    classes=None  # Set to a list of indices to restrict detection to certain classes\n",
    ")\n",
    "\n",
    "def frame_process(frame, input_shape=(640, 640)):\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, input_shape)\n",
    "    img = torch.from_numpy(img)\n",
    "    img = img.float()  # uint8 to fp16/32\n",
    "    img /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    return img\n",
    "    \n",
    "# Video input\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while (True):\n",
    "    try:\n",
    "        clear_output(wait=True)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        input_shape = (640, 640)\n",
    "\n",
    "        im = frame_process(frame, input_shape)\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]\n",
    "        outputs = npu_session.run(None, {npu_session.get_inputs()[0].name: im.permute(0, 2, 3, 1).cpu().numpy()})\n",
    "\n",
    "        # Postprocessing\n",
    "        outputs = [torch.tensor(item).permute(0, 3, 1, 2) for item in outputs]\n",
    "        preds = post_process(outputs)\n",
    "        preds = non_max_suppression(\n",
    "            preds, 0.15, 0.7, agnostic=False, max_det=300, classes=None\n",
    "        )\n",
    "\n",
    "        colors = [[random.randint(0, 255) for _ in range(3)] \n",
    "                for _ in range(len(names))]\n",
    "\n",
    "        # Print class indices in predictions\n",
    "        for pred in preds:\n",
    "            for det in pred:\n",
    "                class_idx = int(det[5])\n",
    "                print(f\"Class index: {class_idx}\")\n",
    "                if class_idx >= len(names):\n",
    "                    print(f\"Warning: Class index {class_idx} is out of range for names list\")\n",
    "\n",
    "        # Filter out predictions with invalid class indices\n",
    "        valid_preds = []\n",
    "        for pred in preds:\n",
    "            if len(pred) > 0:\n",
    "                # Filter predictions to only include valid class indices\n",
    "                valid_indices = [i for i, det in enumerate(pred) if int(det[5]) < len(names)]\n",
    "            \n",
    "                # If we have valid detections, create a tensor with them\n",
    "                if valid_indices:\n",
    "                    valid_pred = pred[valid_indices]\n",
    "                else:\n",
    "                    # Create an empty tensor with the right shape if no valid detections\n",
    "                    valid_pred = torch.zeros((0, 6), device=pred.device)\n",
    "            else:\n",
    "                # Create an empty tensor with the right shape if no detections at all\n",
    "                valid_pred = torch.zeros((0, 6), device=pred.device if len(pred) > 0 else 'cpu')\n",
    "        \n",
    "            valid_preds.append(valid_pred)\n",
    "\n",
    "        # Check if we have any valid predictions before plotting\n",
    "        if any(len(pred) > 0 for pred in valid_preds):\n",
    "            plot_images(\n",
    "                im,\n",
    "                *output_to_target(valid_preds, max_det=6),\n",
    "                frame,\n",
    "                fname=\"output.jpg\",\n",
    "                names=names,\n",
    "            )\n",
    "        else:\n",
    "            # Just display the original frame if no valid detections\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis('off')\n",
    "            plt.title(\"No valid detections\")\n",
    "            plt.show()\n",
    "    except KeyboardInterrupt:\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ryzenai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
