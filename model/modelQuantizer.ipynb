{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.81  Python-3.10.16 torch-2.3.1+cpu CPU (AMD Ryzen AI 9 HX 370 w/ Radeon 890M)\n",
      "Model summary (fused): 72 layers, 11,126,745 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 416, 416) BCHW and output shape(s) (1, 7, 3549) (64.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.2s, saved as 'best.onnx' (42.6 MB)\n",
      "\n",
      "Export complete (1.6s)\n",
      "Results saved to \u001b[1mC:\\Users\\aup\\EcoVision\\model\u001b[0m\n",
      "Predict:         yolo predict task=detect model=best.onnx imgsz=416  \n",
      "Validate:        yolo val task=detect model=best.onnx imgsz=416 data=/content/Recyclable-Items-3/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'best.onnx'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model (best.pt)\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Export the model to ONNX format\n",
    "# imgsz specifies the input image size, which should match the size used during training\n",
    "model.export(format='onnx', imgsz=416)  # 640 is a typical image size, but adjust if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "[QUARK-INFO]: Custom Op compilation start.\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: The custom_op already exists.\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Custom Op compilation already complete.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The configuration of the quantization is Config(global_quant_config=QuantizationConfig(calibrate_method=<PowerOfTwoMethod.MinMSE: 1>, quant_format=<QuantFormat.QDQ: 1>, activation_type=<QuantType.QUInt8: 1>, weight_type=<QuantType.QInt8: 0>, input_nodes=[], output_nodes=[], op_types_to_quantize=[], nodes_to_quantize=[], extra_op_types_to_quantize=[], nodes_to_exclude=[], specific_tensor_precision=False, execution_providers=['CPUExecutionProvider'], per_channel=False, reduce_range=False, optimize_model=True, use_dynamic_quant=False, use_external_data_format=False, convert_fp16_to_fp32=False, convert_nchw_to_nhwc=False, include_sq=False, include_cle=False, include_auto_mp=False, include_fast_ft=False, enable_npu_cnn=True, enable_npu_transformer=False, debug_mode=False, print_summary=True, ignore_warnings=True, log_severity_level=1, extra_options={'ActivationSymmetric': True}))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ryzen-ai-1.3.1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from quark.onnx.quantization.config import Config, get_default_config\n",
    "from quark.onnx.quantization.config.config import QuantizationConfig\n",
    "from onnxruntime.quantization.calibrate import CalibrationMethod\n",
    "from onnxruntime.quantization.quant_utils import QuantType, QuantFormat\n",
    "\n",
    "# Use default quantization configuration\n",
    "quant_config = get_default_config(\"XINT8\")\n",
    "\n",
    "# Define custom quantization configuration\n",
    "# quant_config = QuantizationConfig(calibrate_method=PowerOfTwoMethod.MinMSE,   \n",
    "#                                   activation_type=QuantType.QUInt8,\n",
    "#                                   weight_type=QuantType.QInt8,\n",
    "#                                   enable_npu_cnn=True,\n",
    "#                                   extra_options={'ActivationSymmetric': True})\n",
    "\n",
    "# Defines the quantization configuration for the whole model\n",
    "config = Config(global_quant_config=quant_config)\n",
    "print(\"The configuration of the quantization is {}\".format(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "[QUARK-INFO]: The input ONNX model best.onnx can create InferenceSession successfully\u001b[0m\n",
      "\u001b[31m\n",
      "[QUARK-ERROR]: A calibration data reader is required for static quantization, but none was provided. Please provide a calibration data reader, or alternatively enable random data generation for calibration by setting `config.global_quant_config.extra_options[\"UseRandomData\"]` to `True`.\u001b[0m\n",
      "\u001b[31m\n",
      "[QUARK-ERROR]: A calibration data reader is required for static quantization, but none was provided. Please provide a calibration data reader, or alternatively enable random data generation for calibration by setting `config.global_quant_config.extra_options[\"UseRandomData\"]` to `True`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QUARK_INFO]: Time information:\n",
      "2025-03-02 00:50:00.507664\n",
      "[QUARK_INFO]: OS and CPU information:\n",
      "                                        system --- Windows\n",
      "                                          node --- aup-strix7\n",
      "                                       release --- 10\n",
      "                                       version --- 10.0.26100\n",
      "                                       machine --- AMD64\n",
      "                                     processor --- AMD64 Family 26 Model 36 Stepping 0, AuthenticAMD\n",
      "[QUARK_INFO]: Tools version information:\n",
      "                                        python --- 3.10.16\n",
      "                                          onnx --- 1.16.1\n",
      "                                   onnxruntime --- 1.19.2\n",
      "                                    quark.onnx --- 0.6.0+dba9ca364\n",
      "[QUARK_INFO]: Quantized Configuration information:\n",
      "                                   model_input --- best.onnx\n",
      "                                  model_output --- best1quantized.onnx\n",
      "                       calibration_data_reader --- None\n",
      "                         calibration_data_path --- None\n",
      "                                  quant_format --- QDQ\n",
      "                                   input_nodes --- []\n",
      "                                  output_nodes --- []\n",
      "                          op_types_to_quantize --- []\n",
      "                    extra_op_types_to_quantize --- []\n",
      "                                   per_channel --- False\n",
      "                                  reduce_range --- False\n",
      "                               activation_type --- QUInt8\n",
      "                                   weight_type --- QInt8\n",
      "                             nodes_to_quantize --- []\n",
      "                              nodes_to_exclude --- []\n",
      "                                optimize_model --- True\n",
      "                      use_external_data_format --- False\n",
      "                              calibrate_method --- PowerOfTwoMethod.MinMSE\n",
      "                           execution_providers --- ['CPUExecutionProvider']\n",
      "                                enable_npu_cnn --- True\n",
      "                        enable_npu_transformer --- False\n",
      "                     specific_tensor_precision --- False\n",
      "                                    debug_mode --- False\n",
      "                          convert_fp16_to_fp32 --- False\n",
      "                          convert_nchw_to_nhwc --- False\n",
      "                                   include_cle --- False\n",
      "                                    include_sq --- False\n",
      "                               include_fast_ft --- False\n",
      "                                 extra_options --- {'ActivationSymmetric': True}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A calibration data reader is required for static quantization, but none was provided. Please provide a calibration data reader, or alternatively enable random data generation for calibration by setting `config.global_quant_config.extra_options[\"UseRandomData\"]` to `True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m quantizer \u001b[38;5;241m=\u001b[39m ModelQuantizer(config)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Quantize the ONNX model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m quant_model \u001b[38;5;241m=\u001b[39m \u001b[43mquantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest1quantized.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mcalibration_data_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ryzen-ai-1.3.1\\lib\\site-packages\\quark\\shares\\utils\\log.py:142\u001b[0m, in \u001b[0;36mlog_errors.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    144\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ryzen-ai-1.3.1\\lib\\site-packages\\quark\\onnx\\quantization\\api.py:90\u001b[0m, in \u001b[0;36mModelQuantizer.quantize_model\u001b[1;34m(self, model_input, model_output, calibration_data_reader, calibration_data_path)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput model file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_dynamic_quant:\n\u001b[1;32m---> 90\u001b[0m     \u001b[43mquantize_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcalibration_data_reader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalibration_data_reader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcalibration_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalibration_data_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcalibrate_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalibrate_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mquant_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mactivation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minput_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moutput_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mop_types_to_quantize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop_types_to_quantize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnodes_to_quantize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes_to_quantize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mextra_op_types_to_quantize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_op_types_to_quantize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnodes_to_exclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes_to_exclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mspecific_tensor_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecific_tensor_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexecution_providers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_providers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mper_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mper_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreduce_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moptimize_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m                    \u001b[49m\u001b[43muse_external_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_external_data_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mconvert_fp16_to_fp32\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_fp16_to_fp32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mconvert_nchw_to_nhwc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_nchw_to_nhwc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minclude_sq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_sq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minclude_cle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_cle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minclude_auto_mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_auto_mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minclude_fast_ft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_fast_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m                    \u001b[49m\u001b[43menable_npu_cnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_npu_cnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m                    \u001b[49m\u001b[43menable_npu_transformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_npu_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdebug_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mprint_summary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mextra_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     quantize_dynamic(model_input\u001b[38;5;241m=\u001b[39mmodel_input,\n\u001b[0;32m    123\u001b[0m                      model_output\u001b[38;5;241m=\u001b[39mmodel_output,\n\u001b[0;32m    124\u001b[0m                      op_types_to_quantize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mop_types_to_quantize,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m                      debug_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdebug_mode,\n\u001b[0;32m    132\u001b[0m                      extra_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mextra_options)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ryzen-ai-1.3.1\\lib\\site-packages\\quark\\shares\\utils\\log.py:142\u001b[0m, in \u001b[0;36mlog_errors.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    144\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ryzen-ai-1.3.1\\lib\\site-packages\\quark\\onnx\\quantize.py:198\u001b[0m, in \u001b[0;36mquantize_static\u001b[1;34m(model_input, model_output, calibration_data_reader, calibration_data_path, quant_format, calibrate_method, input_nodes, output_nodes, op_types_to_quantize, extra_op_types_to_quantize, per_channel, reduce_range, activation_type, weight_type, nodes_to_quantize, nodes_to_exclude, optimize_model, use_external_data_format, execution_providers, enable_dpu, enable_npu_cnn, enable_npu_transformer, specific_tensor_precision, convert_fp16_to_fp32, convert_nchw_to_nhwc, debug_mode, include_cle, include_sq, include_fast_ft, include_auto_mp, print_summary, extra_options)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calibration_data_reader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m extra_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUseRandomData\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 198\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    199\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA calibration data reader is required for static quantization, but none was provided. Please provide a calibration data reader, or alternatively enable random data generation for calibration by setting `config.global_quant_config.extra_options[\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUseRandomData\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]` to `True`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    200\u001b[0m         )\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m         calibration_data_reader \u001b[38;5;241m=\u001b[39m RandomDataReader(model_input,\n\u001b[0;32m    203\u001b[0m                                                    input_shape\u001b[38;5;241m=\u001b[39mextra_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomDataReaderInputShape\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}),\n\u001b[0;32m    204\u001b[0m                                                    input_data_range\u001b[38;5;241m=\u001b[39mextra_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    205\u001b[0m                                                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomDataReaderInputDataRange\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "\u001b[1;31mValueError\u001b[0m: A calibration data reader is required for static quantization, but none was provided. Please provide a calibration data reader, or alternatively enable random data generation for calibration by setting `config.global_quant_config.extra_options[\"UseRandomData\"]` to `True`."
     ]
    }
   ],
   "source": [
    "from quark.onnx import ModelQuantizer\n",
    "# Create an ONNX Quantizer\n",
    "quantizer = ModelQuantizer(config)\n",
    "\n",
    "# Quantize the ONNX model\n",
    "quant_model = quantizer.quantize_model(model_input = \"best.onnx\", \n",
    "                                       model_output = \"best1quantized.onnx\", \n",
    "                                       calibration_data_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ryzen-ai-1.3.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
